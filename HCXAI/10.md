# Explainable Artificial Intelligence: Human-centered Perspective
- 2021年
- Hana Kopecká撰写的文章《Explainable Artificial Intelligence: Human-centered Perspective》探讨了可解释人工智能（XAI）在人类中心视角下的发展。文章指出，随着人工智能领域在计算机视觉和自然语言处理等方向取得巨大进展，其在伦理道德方面的问题也日益凸显，如COMPAS软件在预测犯罪再犯率上的种族歧视问题。作者强调，现有XAI研究多聚焦于解释作为产品或过程的特性，而忽视了接收者在解释过程中的关键作用。

## 1. Introduction

文章开篇引入可解释人工智能（XAI）的研究背景，指出XAI在AI社区的重要性日益提高，同时也揭示了AI领域在人口统计学上的多样性危机，即AI研究员的人口多样性不足。作者提出疑问，这种多样性危机是否会导致XAI系统仅迎合特定群体，而忽视或排斥其他未充分代表的群体。

## 2. Explainable Artificial Intelligence

文章详细分析了XAI系统的设计目标，根据不同用户群体（如专家和新手）需求的差异，强调了XAI系统在提高透明度、构建用户信任、降低偏见风险和帮助用户评估数据隐私方面的设计重点。作者指出，解释不仅是一个产品和过程，更是一种认知和社会过程，包含解释者确定解释的因果链、选择重要元素的认知过程，以及将解释传递给接收者的社会过程。

## 3. Culture, Cognition and Perception

文章深入探讨了文化、认知和感知之间的关系。作者指出，认知心理学和认知社会学研究表明，个体的成长环境影响其感知和认知方式，进而影响对AI系统解释的偏好。文章强调，为设计出符合用户认知倾向的XAI系统，需要理解不同文化背景下用户与AI系统交互方式的差异。

## 4. Intersectional Feminism

文章引用交叉女性主义理论，指出XAI社区在考虑用户身份时，往往只关注用户对AI系统的熟悉程度或应用领域，而忽视了认知和感知倾向的差异。作者批评AI领域及其领导层缺乏多样性，并引用AI Now研究所的报告，揭示了AI专业人员中女性比例极低的现状，强调这种多样性缺失可能导致XAI系统在无意中为特定用户群体优化，而对其他群体不够优化。

## 5. Conclusion

文章总结了作者的研究定位，即在认知心理学、认知社会学、交叉女性主义和人工智能的交叉领域，研究用户社会文化背景对其认知风格及AI解释需求的影响。作者强调了理解用户认知过程的重要性，以设计出更具包容性和以人类为中心的AI系统。

本文通过跨学科视角，强调了在设计可解释AI系统时考虑用户社会文化背景的重要性，旨在推动AI系统向更具包容性和人类中心化方向发展。

# 《A user-centered explainable artificial intelligence approach for financial fraud detection》研究总结
- 2023 年

## 一、研究背景与目标
### （一）研究背景
1. **AI在金融欺诈检测中的应用现状**  
   机器学习（ML）因高预测性能被广泛用于金融欺诈检测，但模型可解释性不足成为实际应用的主要挑战，引发监管机构和伦理学家的担忧。
2. **可解释人工智能（XAI）的重要性**  
   XAI旨在平衡模型预测性能与可解释性，帮助用户理解模型逻辑、建立信任并辅助决策。现有研究多聚焦开发者需求，缺乏对外部利益相关者（如监管者、审计师、分析师、投资者）解释需求的关注。

### （二）研究目标
提出一种**用户中心的可解释金融欺诈检测方法**，通过集成预测模型与基于Shapley值的解释框架，为外部利益相关者提供准确预测和可理解的解释，弥合ML应用与利益相关者决策需求之间的鸿沟。

## 二、数据与样本选择
### （一）数据来源与范围
- **数据范围**：2007-2020年中国非金融企业的37,502个公司年度观测值，含432个欺诈样本（经监管机构定罪）和37,070个非欺诈样本。
- **特征选取**：直接提取资产负债表、利润表和现金流量表的原始财务数据，涵盖124个特征（具体见附录），避免人为特征工程的局限性，充分释放ML模型潜力。

### （二）数据集划分
- **训练集（2007-2017年）**：进一步划分为训练子集（2007-2015年）和验证集（2016-2017年），用于超参数调优（网格搜索法）。
- **测试集（2018-2020年）**：评估模型最终性能。

## 三、研究方法与框架
### （一）外部利益相关者的解释需求分析
| 利益相关者 | 局部解释需求（单个观测） | 全局解释需求（整体模型） |
|------------|--------------------------|--------------------------|
| **监管者** | 特征贡献、预测逻辑       | 特征影响、特征交互       |
| **审计师** | 特征贡献、预测逻辑       | 特征影响、特征交互       |
| **分析师** | 特征贡献                 | 特征影响                 |
| **投资者** | 特征贡献                 | 特征影响                 |
*依据表1总结，监管者和审计师对解释的需求更全面，需覆盖局部和全局层面的多维度分析。*

### （二）提出的方法框架
#### 1. **集成模型构建（步骤1-3）**
- **欠采样处理**：针对类别不平衡问题，生成多个欠采样训练子集（每个子集包含全部欺诈样本和随机选取的等数量非欺诈样本）。
- **基分类器训练**：每个子集训练一个XGBoost分类器，利用其自动处理缺失值的能力。
- **模型组合与选择**：通过多数投票法集成基分类器，选择与最终预测结果一致的基分类器作为“正确模型”集合。

#### 2. **基于SHAP的解释生成（步骤4-5）**
- **局部解释**：计算“正确模型”的Shapley值均值，揭示单个观测中各特征对预测的贡献（如预付款项、商誉等特征的正负影响），并通过决策图对比不同基分类器的预测逻辑。
- **全局解释**：对所有观测的Shapley值绝对值取平均，分析特征重要性排序（如预付款项、商誉、非控制性权益等为关键特征）及特征间交互效应（如营业利润与商誉的协同影响）。

## 四、实证分析结果
### （一）模型性能
- **预测准确性**：集成模型在测试集上的AUC为0.79，显著优于单一XGBoost模型（AUC=0.58）及欠采样、过采样等传统方法。
- **解释有效性**：
  - **局部解释示例**：观测A中“预付款项”贡献最大（+0.26），观测B中“商誉”贡献最大（+0.2），体现个体差异。
  - **全局解释发现**：商誉作为新兴重要特征，与会计文献中“管理层可能操纵商誉减值虚增利润”的结论一致；预付款项等关联交易特征与既往研究吻合。

### （二）特征分析
- **关键特征**：预付款项、商誉、非控制性权益、营业利润等，其中商誉的高值与欺诈风险正相关（图5(a)）。
- **特征交互**：营业利润的影响因商誉或总资产的不同取值而变化，表明特征间存在复杂协同效应（图6）。

## 五、结论与展望
### （一）主要结论
- 提出的**用户中心XAI框架**通过集成模型与SHAP解释，有效满足监管者、审计师等外部利益相关者的局部和全局解释需求。
- 原始财务数据的全面利用及欠采样集成策略提升了模型预测性能，SHAP值为特征分析提供了理论可靠的解释依据。

### （二）未来研究方向
1. 引入Shapley Lorenz值等其他XAI技术进行对比分析。
2. 扩展公平性评估等新的信息需求。
3. 开发基于预测性能的模型选择程序，优化解释框架。

## 六、数据与代码可用性
数据可通过请求获取，研究受国家自然科学基金资助，作者声明无利益冲突。
# Human-centered XAI: Developing design patterns for explanations of clinical decision support systems
- 2021年
## 摘要
本文提出了一种人本设计方法（DoReMi 方法），用于开发可解释的人工智能（XAI）。该方法包含三个部分：领域分析、需求收集与评估，以及多模态交互设计与评估。通过在儿童健康诊断领域的一个案例研究，展示了如何将人本设计方法应用于临床决策支持系统（CDSS）的解释开发。

## 1. 引言
- XAI 研究主要关注提高机器学习模型的透明度，但缺乏将人类因素整合到开发过程中的实际方法。
- 人本 XAI 方法强调解释的目的是回应特定请求，需理解 AI 系统的主要目的、用户及使用场景。
- 以 CDSS 为例，解释对临床相关性及长期使用至关重要，需深入理解医疗决策过程和临床医生的解释需求。

## 2. 人本 XAI 设计
- 人本 XAI 方法需整合人类因素，通过迭代涉及用户开发有用解释。
- 人本设计方法聚焦于何时、向谁、如何解释，通过用户研究（如访谈、场景、焦点小组和问卷）确定用户价值观及人 - AI 交互的社会和操作环境。
- DoReMi 方法基于人本设计原则，应用于 XAI 研究与开发，生成可重用的通用设计模式。

## 3. DoReMi 方法流程
- 包括领域分析、需求收集与评估、多模态交互设计与评估三个部分。
- **领域分析**：理解系统使用场景，确定解释需求和相关信息。
- **需求收集与评估**：识别用户对解释的需求和上下文依赖性。
- **多模态交互设计与评估**：设计解释呈现方式，创建通用设计模式。
- 生成设计模式库，指导 XAI 系统设计。

## 4. CDSS 领域分析
- CDSS 的目的是通过信息收集、分析、结构化和呈现，帮助用户做出更好的决策，提高医疗质量和患者护理。
- 成功采用 CDSS 的关键在于其能向临床医生解释诊断建议，建立信任。
- 医学领域解释通常包含支持和反证据、对比案例、潜在鉴别诊断等信息。

## 5. CDSS 解释需求收集与评估
- 通过用户研究确定 CDSS 应提供的解释类型和上下文依赖性。
- 研究对象为六名儿科医生，通过问卷和访谈收集数据。
- 研究结果表明，医生对大多数信息元素的重视程度较高，且存在个体差异。

## 6. CDSS 解释的多模态交互设计与评估
- 基于用户研究结果，设计 UI 设计模式，涵盖所有信息元素。
- 开发了 12 个 UI 设计模式，如类别信息、可用 / 相关信息、确定性等。
- 第二个用户研究评估了这些设计模式，结果表明医生对解释的完整性和可理解性有较高评价。

## 7. 研究结论与展望
- DoReMi 方法为开发符合用户需求的 XAI 解释提供了一种有效途径。
- 研究生成了儿童健康领域的 CDSS 解释用户需求和 UI 设计模式。
- 未来研究将扩展到更多使用场景和用户群体，进一步测试设计模式的通用性。
- 计划将解释和设计模式整合到 CDSS 原型中，进行更深入的测试和评估。

## 8. 详细设计模式示例
- **DP4：支持 / 反驳信息**：展示支持和反驳分类的信息，使用颜色区分正负贡献特征。
- **DP7：对比解释和阈值**：解释为何是该分类而非其他，包括阈值信息。
- **DP10：与其他案例比较**：使用平行坐标技术展示当前案例与其他相关案例的相似性和差异性。

## 9. 研究贡献与意义
- 提供了儿童健康领域 CDSS 的用户需求和设计模式。
- 展示了如何将专家用户纳入开发过程，开发通用设计解决方案。
- 强调了 XAI 开发中多学科团队合作的重要性。

## 10. 研究局限与未来工作
- 当前研究主要关注解释的内容和形式，未来需进一步研究解释的使用效果。
- 计划开发 XAI 系统原型，进行用户交互测试，结合主观和客观测量评估解释效果。
- 探索解释要求和效果随时间的变化，以及解释的潜在副作用。
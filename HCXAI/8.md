# Explainable medical imaging AI needs human-centered design: guidelines and evidence from a systematic review
- 2022年
## 研究背景与意义
- **医疗影像AI的透明性需求**：文章强调在医疗影像分析中，机器学习（ML）模型的透明性（Transparency）至关重要。透明性不仅关乎模型如何得出结论，更涉及其与用户（如临床医生）之间的信任建立。这对于减少医疗误诊、避免算法偏见以及提升临床决策的可靠性具有重要意义。
- **现有研究局限性**：当前透明ML研究多聚焦于技术可行性，却忽视了终端用户（如临床医生）的需求与知识背景。这种“技术中心”而非“用户中心”的开发模式，可能导致模型在实际临床场景中难以理解和应用，最终限制其价值。

## 研究方法
- **系统性文献回顾**：作者检索了PubMed、EMBASE和Compendex数据库中2012至2021年的文献，筛选出68篇符合标准的研究文章进行分析。
- **主题分类**：基于初始文献综述，作者将透明ML设计的考量因素归纳为六个主题（IN、T、R、PR、T），并构建了INTRPRT指南。

## 关键发现与观点
### 现状分析
- **用户研究缺失**：在68篇研究中，仅33篇由跨学科团队撰写，且无一研究在模型构建前进行形成性用户研究。这表明大多数透明ML研究未以用户需求为驱动。
- **透明性验证不足**：仅3篇研究通过实证用户测试验证了透明性主张，其余研究多依赖定性分析（如展示像素归因可视化）或基于开发者直觉假设透明性技术的有效性。

### INTRPRT指南核心内容
1. **明确临床场景与用户需求**：设计透明ML算法的第一步是精准定义临床任务、约束条件及终端用户特征（如用户的专业背景、决策责任等）。
2. **透明性证据等级**：作者提出四级证据等级（从无证据到迭代开发证据），强调开发者需根据用户反馈逐步验证透明性设计，而非单纯依赖假设。
3. **技术实现与用户沟通**：透明性技术（如注意力机制、可视化方法）需与用户知识水平相匹配，以确保用户能理解模型输出并据此采取行动。
4. **多维度评估**：透明ML系统需同时评估任务性能（如分类准确率）和人类因素（如用户信任、满意度），并通过迭代设计不断优化。

## 研究意义与未来方向
- **推动“以用户为中心”的AI设计**：文章提出的INTRPRT指南为医疗影像AI的透明性设计提供了系统框架，强调将用户研究融入算法开发全过程。
- **跨学科合作必要性**：作者呼吁加强AI开发者与临床医生、认知科学家等多领域专家的合作，以弥合技术与医学知识之间的鸿沟。
- **透明性技术的多样化探索**：文章指出，针对不同用户群体（如护士、患者）和任务类型（如预测、分割），需开发差异化的透明性技术，并通过实证研究验证其有效性。

## 成功案例与挑战
- **成功案例**：部分研究通过迭代设计和用户参与（如数字病理学AI工具的开发），成功提升了模型的可解释性和用户接受度。
- **主要挑战**：包括获取临床用户参与的伦理限制、医疗数据的复杂性（如非结构化数据）、以及AI设计者缺乏人因工程学训练等。

总体而言，文章通过系统性回顾和指南提案，揭示了当前医疗影像AI透明性研究的技术导向局限，并强调了“以用户为中心”的设计原则对于提升AI临床应用价值的关键作用。
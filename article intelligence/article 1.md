# A new method for measuring the originality of academic articles based on knowledge units in semantic networks

### 1. 研究对象

-   **研究领域与背景**
    -   本文属于科学计量学（Scientometrics）领域，专注于学术论文质量的客观评价方法研究。
    -   研究背景指出，传统的基于引用的外部指标（如被引次数）更多地反映论文的“影响力”而非其内在“质量”，并且受到作者声誉等非学术因素的干扰。因此，学术界逐渐转向基于论文内容的质量评价，其中“原创性”被视为一个核心的衡量维度。然而，对原创性进行客观、定量的评估一直是一个难题，现有方法存在诸多局服从性。

-   **具体研究对象或数据集**
    -   **背景知识网络构建语料库**：使用微软学术搜索（Microsoft Academic Search）收集了截至2014年发表在所有学科Q1期刊上的超过3000万篇英文论文的摘要，涵盖22个学科，用于构建底层的语义网络。
    -   **核心分析数据集**：
        1.  **图书情报学（LIS）**：分析了2014年至2018年间发表在5种核心期刊（如 *Journal of Informetrics*, *Scientometrics* 等）上的3757篇论文。
        2.  **教育心理学（Educational Psychology）**：选取了该领域6种期刊的2015篇论文进行通用性验证。
        3.  **碳纳米管（Carbon Nanotubes）**：选取了该领域3种期刊的3962篇论文进行通用性验证。
    -   **高质量论文验证集**：选取了2014年至2018年间在碳纳米管和教育心理学领域被公认为具有高科学质量或原创性的59篇论文，包括发表在 *Nature* 和 *Science* 上的论文、MDPI评选的代表前沿研究的“特稿论文”（Feature papers）以及诺贝尔奖获奖者的论文。

### 2. 研究方法

-   **使用的理论框架与算法**
    -   **理论框架**：研究基于“知识组合”的观点，但对其进行了扩展。论文认为，原创性不仅体现在新的知识单元组合，更体现在知识单元之间新颖的“语义关系”中。为此，论文提出了一个基于“知识单元语义网络”的原创性测量框架。
    -   **核心算法与技术**：
        1.  **自然语言处理（NLP）**：用于从论文摘要中提取结构化的知识信息。
        2.  **依赖句法分析（Dependency Parsing）**：用于识别句子中词语间的语法关系，从而提取知识单元及其相互关系。
        3.  **Sentence-BERT**：一种基于Transformer的深度学习模型，用于计算知识单元（短语）之间的语义相似度。
        4.  **网络分析（Network Analysis）**：将知识单元作为节点、关系作为边，构建大规模的知识网络。
        5.  **潜在狄利克雷分配（LDA）**：一种主题模型，用于在验证环节对论文主题进行聚类，以检验原创性得分与主题集中度的关系。

-   **模型 / 技术详解**
    -   **知识单元与关系提取**：
        -   **架构**：采用NLTK和Stanford NLP工具包。
        -   **流程**：首先对摘要文本进行词性标注（PoS tagging）和词形还原（Lemmatization）。然后，利用依赖句法分析来解析句子结构。
        -   **输入**：论文摘要的句子。
        -   **输出**：
            -   **知识单元（Knowledge Unit）**：被定义为能够代表一个相对完整知识的专业短语，通常是从名词短语（NP）结构（如形容词-名词，名词-名词等）中提取。例如，从句子中可以提取出 "in-house use data collection" 这样的知识单元。
            -   **关系（Relationship）**：知识单元之间的连接关系，通过介词（如 `on`, `to`）、连词（如 `and`）等识别。例如，`to` 表示目的或结果的递进关系，`on` 表示限定关系，`and` 表示并列关系。
    -   **Sentence-BERT 语义相似度模型**：
        -   **架构**：采用基于BERT的双胞胎网络（Siamese Network）架构。两个相同的BERT网络分别处理输入的两个句子（在这里是知识单元），然后通过一个池化层（Pooling Operation，本文使用对所有输出向量取均值的方式）得到固定维度的句子向量。
        -   **输入**：两个知识单元，如 "Sentence A" 和 "Sentence B"。
        -   **推理流程**：通过计算两个输出向量 `u` 和 `v` 之间的余弦相似度（cosine-similarity）来得到它们的语义相似度得分，范围在-1到1之间。
        -   **优势**：与传统BERT相比，它专门为句子/短语级别的相似度计算进行了优化，速度快且能保证准确性。它解决了传统方法中简单拆分词语导致语义丢失的问题。
    -   **知识单元网络构建**：
        -   **架构**：一个由“知识单元”、“关系”和“相似知识单元”构成的网络。
        -   **流程**：
            1.  将从语料库中提取的所有知识单元作为网络的“节点”。
            2.  使用训练好的Sentence-BERT模型计算任意两个知识单元节点间的语义相似度。
            3.  若两个知识单元的相似度大于预设阈值（本文为0.6），则认为它们高度相似，并在它们之间建立连接。每个节点下都关联着一组与其高度相似的知识单元。
            4.  将从句法分析中提取的“关系”（如TO/V, IN, CC）作为连接知识单元的“边”。
        -   **输出**：一个大规模、跨学科的背景知识网络。

-   **关键公式或模型（如有）**
    -   **原创性指数（Originality Index, O）计算公式**：
        $$O=\frac{\sum N.SLink\times AVG.S}{N.Link}$$
        -   $O$：论文的原创性指数。**该指数越低，表示原创性越高**。
        -   $N.Link$：待评估论文摘要中包含的所有知识链接（semantic link）的总数。
        -   $N.SLink$：对于论文中的每一个知识链接，在背景知识网络中找到的与其相似的链接数量。
        -   $AVG.S$：该知识链接与其所有相似链接之间的平均语义相似度（由Sentence-BERT计算）。
        -   $\sum$：对论文中所有知识链接的计算结果求和。

### 3. 研究内容

-   **主要研究问题**
    -   如何构建一个基于论文内容、客观且可量化的新方法来衡量学术论文的原创性？
    -   该方法如何克服传统引用分析和简单关键词组合分析的局限性？
    -   该方法的有效性如何？它与其他原创性/颠覆性指标有何关系？
    -   该方法是否具有跨学科的普适性？

-   **论文各章节的核心工作**
    -   **第一、二章（引言与文献综述）**：提出问题，明确了将“原创性”作为核心评价指标的重要性，并回顾了现有三类原创性测量方法（知识成分分析、引文网络分析、知识组合分析）及其缺陷，为提出新方法奠定了理论基础。
    -   **第三章（数据与方法）**：详细阐述了研究的数据来源和原创性测量方法的六个步骤：(a) 收集数据 -> (b) 提取知识单元与关系 -> (c) 计算语义相似度 -> (d) 构建知识网络 -> (e) 分析待评文章 -> (f) 计算原创性指数。
    -   **第四章（结果与分析）**：核心的实证部分。
        1.  首先，应用该方法分析了LIS领域的论文，并按“研究主题”、“研究方法”、“研究成果”三个维度展示了2014-2018年的原创性变化趋势。
        2.  其次，将本研究提出的方法与两种主流的引文网络分析方法（Uzzi的Z-score和Wu的颠覆性指数DI）以及一种知识组合方法（Yan等的关键词组合法）进行对比，分析它们之间的相关性。
        3.  再次，将方法应用于另外两个学科（教育心理学、碳纳米管），以检验其通用性。
        4.  最后，使用一个包含公认高质量论文的数据集，对比四种方法在识别这些顶尖成果上的表现。
    -   **第五章（讨论与结论）**：总结研究发现，重申了新方法的优势，即通过构建语义网络更准确地捕捉了内容的原创性，同时承认了研究的局限性，如未对不同论文类型（如综述、方法学论文）赋权，以及内容分类可以更细化。

### 4. 研究结论

-   **重要发现与定量/定性结果**
    -   **原创性趋势**：在所分析的三个学科（LIS、教育心理学、碳纳米管）中，论文的原创性总体上都随时间推移而提高（即原创性指数O呈下降趋势）。
    -   **内容维度差异**：在LIS领域，论文的“研究方法”部分原创性最高，其次是“研究主题”，最后是“研究成果”。
    -   **方法有效性验证**：通过LDA主题模型分析发现，本方法判定为高原创性的论文，其主题分布更分散；低原创性的论文主题更集中，这从侧面验证了方法的有效性。
    -   **与其他方法的对比**：
        -   本研究提出的原创性指数与基于引文网络的Z-score和颠覆性指数（DI）**没有明显的相关性**。作者认为这是因为引文网络更多反映知识传承而非知识本身，且受非学术因素影响。
        -   与基于关键词组合的方法相比，仅在“研究主题”维度上观察到**正相关**，而在“研究方法”和“研究成果”上无相关性。这表明关键词主要反映研究主题，而本文的方法能更全面地覆盖论文内容。
    -   **跨学科普适性**：该方法能够应用于不同学科，但得分范围和变化趋势因学科范式（如社会科学与工程学）、研究规模（论文产出量）等特性而异。例如，碳纳米管领域的论文数量远超LIS，导致其知识在网络中占比更高，相似链接更多，得分也相对更高（原创性更低）。
    -   **对高质量论文的识别能力**：在对59篇公认的高质量论文进行测试时，本研究提出的方法比Z-score、DI和关键词组合法**更有效地识别出了这些论文的高原创性**。

-   **对学术或实际应用的意义**
    -   **理论意义**：提出了一种全新的、基于内容语义网络的科学计量学评价范式，将原创性评估从依赖外部指标或简单内容元素，推进到对知识结构和语义关系的深度分析层面。
    -   **实际应用**：提供了一个更客观、自动化、可重复的工具，可用于辅助科研管理、期刊评价、基金评审等场景，以识别真正具有创新性的研究，摆脱唯“引用”论或唯“影响因子”论的局限。

### 5. 创新点、研究问题与出发点

-   **创新点逐条列出**
    1.  **从“关键词”到“知识单元”的深化**：不满足于使用作者提供或简单抽取的关键词，而是通过依赖句法分析从摘要全文中提取结构化的、能代表完整语义的“知识单元”（短语）。
    2.  **从“组合”到“语义网络”的升级**：不仅考虑知识单元的出现和组合，更关注它们之间的“语义关系”（如递进、限定、并列），并以此构建了一个大规模的语义网络作为评估背景。
    3.  **标准化与语义消歧**：利用先进的Sentence-BERT模型计算语义相似度，有效解决了同一概念不同表述（如同义词、不同措辞）的问题，使得度量更加准确。
    4.  **多维度、可定制的评估框架**：将论文内容划分为“研究主题”、“研究方法”和“研究成果”三个部分进行独立评估，这允许根据不同评价需求（如更看重方法创新或理论创新）对各部分赋予不同权重。

-   **作者提出的核心问题**
    -   如何才能超越传统的引用计数和简单的内容分析，开发一种能够客观、准确、深入地衡量学术论文内容本身原创性的量化方法？

-   **研究动机与假设**
    -   **动机**：现有评价方法存在严重缺陷。引用等外部指标衡量的是“影响力”而非“质量”，且有延迟和偏见。同行评议主观且成本高。基于关键词等内容的分析方法过于片面，无法捕捉论文内容的复杂性和深层结构。
    -   **假设**：一篇论文的原创性，体现在其内部知识结构（即知识单元及其语义链接）相对于整个学科知识背景的“新颖”程度。这种新颖程度可以通过计算其知识链接在预先构建的大规模语义网络中的“罕见性”（即相似链接少）和“疏远度”（即与相似链接的平均相似度低）来量化。

### 6. 创新点与出发点的验证与实现

-   **实验/仿真/原型设计流程**
    1.  **数据收集与预处理**：
        -   **构建背景网络**：从Microsoft Academic Search下载超3000万篇论文摘要作为语料库。
        -   **准备测试集**：收集LIS、教育心理学、碳纳米管三个领域的特定期刊在2014-2018年发表的论文摘要，以及一个高质量论文集。
    2.  **知识单元提取与网络构建**：
        -   对语料库中的每一篇摘要，通过NLP流程（词性标注、词形还原、依赖句法分析）提取“知识单元”及其“关系”。
        -   将所有知识单元作为节点，使用Sentence-BERT计算节点间的语义相似度，相似度>0.6的节点被视为高度相似并连接。将“关系”作为节点间的边，构建起一个庞大的背景知识网络。
    3.  **待评论文分析**：
        -   对一篇待评估的论文摘要，首先通过预设的特征词和句子位置规则，将其句子划分到“研究主题”、“研究方法”、“研究成果”三个类别。
        -   对每个类别的句子，同样使用NLP流程提取其内部的“知识链接”（即由知识单元和关系构成的结构）。
    4.  **原创性计算**：
        -   将待评论文的每个知识链接，与背景知识网络进行匹配。
        -   对每个链接，查找网络中与其相似的链接数量（`N.SLink`）和这些相似链接的平均相似度（`AVG.S`）。
        -   将这些值代入公式 (1)，计算出论文在三个维度上的原创性指数 `O`。
    5.  **验证与对比**：
        -   **内部验证**：使用LDA模型对各年的论文进行主题聚类。将论文按原创性指数排名，观察不同原创性区间的论文在主题分布上的差异。
        -   **外部对比**：计算测试集中所有论文的Z-score、DI指数和关键词组合（KC）得分。将这些得分与本研究的原创性指数进行相关性分析和可视化对比。
        -   **“金标准”验证**：对59篇高质量论文，分别用四种方法计算其原创性得分，并将其转化为在各自年份和学科内的百分位排名，对比哪种方法能更稳定地给予这些论文更高的排名（即更高的原创性）。

-   **数据集、参数、评价指标**
    -   **数据集**：如“研究对象”部分所述的四个数据集。
    -   **关键参数**：
        -   Sentence-BERT模型：批量大小为8，学习率为3e-5，使用Adam优化器。
        -   知识网络构建：语义相似度阈值为0.6。
        -   LDA模型：主题数K由困惑度（perplexity）确定，每年每类都不同。
    -   **评价指标**：
        -   **核心指标**：本文提出的原创性指数 `O`。
        -   **对比指标**：Z-score、颠覆性指数（DI）、新关键词组合比例（KC）。
        -   **验证指标**：LDA聚类后的主题集中度。

-   **结果对比与可视化描述**
    -   **LDA验证**：图 B2-B4 的散点图显示，原创性排名靠后（图中右侧）的论文倾向于聚集在少数几个大节点上，表明主题集中；而原创性排名靠前（图中左侧）的论文则分布在大量小节点上，表明主题分散。这支持了该方法有效性的假设。
    -   **与其他方法对比**：
        | 方法 (Method) | 提出者 (Proposer) | 核心思想 (Core Idea) | 本文结论 (Paper's Conclusion) |
        |---|---|---|---|
        | **Z-score** | Uzzi et al. (2013) | 新颖性体现在对罕见期刊组合的共引。 | 无明显关系；未关注知识本身。 |
        | **Disruption Index (DI)** | Wu et al. (2019) | 颠覆性论文会开辟新的引用路径，而非巩固旧的。 | 无明显关系；引用网络受非知识因素影响。 |
        | **Keyword Combination (KC)** | Yan et al. (2020) | 新颖性体现在新出现的关键词配对。 | 仅在“研究主题”上有正相关；关键词无法全面反映内容。 |
    -   **高质量论文验证**：图5的箱线图清晰地展示了，对于公认的高质量论文，本研究的方法（RT, RM, RR）给出的百分位排名（越低越好）显著优于其他三种方法。例如，在“自然与科学论文”组中，RT（研究主题）的平均排名在20%分位左右，而DI和Z-score的平均排名则在70%以上，表明本方法能更准确地识别其原创性。

-   **作者如何证明方法有效性**
    作者通过一个逻辑严密的多层次证据链来证明其方法的有效性：
    1.  **理论的合理性**：首先从理论上剖析了现有方法的缺陷，并论证了其新方法（基于语义网络）在概念上的优越性。
    2.  **内部一致性验证**：通过LDA主题模型，证明其原创性指数与一个公认的、与创新相关的特征（主题多样性）相符。
    3.  **差异化比较**：通过与主流方法的实证对比，表明其测量的是一个不同的、更侧重于内容本身的维度，而非简单地重复或替代现有指标。
    4.  **外部“金标准”校准**：通过在一个由顶尖成果组成的“金标准”数据集上进行测试，证明其方法比其他方法更具识别顶尖创新的能力。
    5.  **普适性检验**：通过在三个差异巨大的学科上成功应用，证明该方法框架具有跨学科推广的潜力。